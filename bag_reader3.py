#!/usr/bin/env python

#   Copyright (c) 2014 David Anthony
#
#   This program is free software; you can redistribute it and/or modify
#   it under the terms of the GNU General Public License as published by
#   the Free Software Foundation; either version 2 of the License, or
#   (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
from __future__ import print_function
import argparse
import os
import rosbag
import roslib
import sys
import subprocess, yaml
roslib.load_manifest('rosbag')

import datetime as dt
import math 
import fractions
from fractions import Fraction

import numpy as np
import time
import rosbag
import rospy
from rospy import Duration
from rospy import Time
from sets import Set
import xml.etree.ElementTree as ET
from array import *

hz_dict = {}
bag_topics = []
bag_array = []
start_time = Duration(-1)
time_deltas = []

def build_parser():
    """Creates parser for command line arguments """
    parser = argparse.ArgumentParser(description='Bag reader')
    parser.add_argument('-b', '--bag',
                        help='Bag files to read',
                        required=True,
                        nargs='+',
                        type=str)
    parser.add_argument('-i', '--info',
                        help='List topics and fields within topics',
                        required=False,
                        action='store_true')
    parser.add_argument('-s', '--stats',
                        help='Display how many messages were published on each topic',
                        required=False,
                        action='store_true')
    #parser.add_argument('-t', '--topic',
    #                    help='Topics to write to csv file',
    #                    required=False,
    #                    action='store',
    #                    nargs='+',
    #                    type=str)
    parser.add_argument('-o', '--output_file',
                        help='Output file name',
                        required=False,
                        action='store',
                        nargs='+',
                        dest='out_file',
                        type=str)

    return parser


def validate_args(cmd_args):
    """ Validates the arguments parsed by the parser generated in the build_parser() function. We
        must always have a bag file, but other than the bag file, there are valid combinations of
        different arguments.
    """
    valid = cmd_args.bag is not None

    if not valid:
        print('Must specify a bag file')

    if valid:
        for bag_file in cmd_args.bag:
            valid = os.path.isfile(bag_file)
            if not valid:
                print('Invalid bag file: ' + bag_file)
                break

    if valid:
        """ 1. If info is requested, that is the only argument allowed.
            2. Topics and output files may be specified.
            3. Topics may be specified. Output file names will be autogenerated.
            4. Stats may be requested.
        """
        #ops_requested = [False] * 3
        ops_requested = [False] * 2
        ops_requested[0] = cmd_args.info
        #ops_requested[1] = (cmd_args.topic is not None)
        #ops_requested[2] = cmd_args.stats
        ops_requested[1] = cmd_args.stats
        
        valid = (sum(ops_requested) == 0)
        if not valid:
            print('Must specify either bag info, a topic and output file, or statistics')

        if valid and cmd_args.out_file is not None:
            valid = True # (len(cmd_args.out_file) == len(cmd_args.bag) * len(cmd_args.topic))
            if not valid:
                print('Number of output files must be enough for bags and topics passed in')

    return valid


def display_bag_info(bag_name):
    global bag_info
    """ Lists every topic in the bag, and the fields within each topic. Data is sent to the standard
        output. This assumes that every message for a given topic has the same format in the bag.
        This can sometimes break. For example, if a topic has an array of geometry_msgs/Vector3 in
        it, and the first message has an empty array, the components of the Vector3 will not be
        listed. Output will typically look like the following header message published on the
        /ns/dummy topic name:

        /ns/dummy
            header
                seq
                stamp
                    secs
                    nsecs
    """
    """ Get the bag file summary info """
    bag_info = yaml.load(subprocess.Popen(
        ['rosbag', 'info', '--yaml', bag_name], stdout=subprocess.PIPE).communicate()[0])
    """ Get the topics in the bag """
    bag_topics = bag_info['topics']
    bag = rosbag.Bag(bag_name)
    """ For every topic in the bag, display its fields. Only do this once per topic """
    for topic in bag_topics:
        for _, msg, _ in bag.read_messages(topics=topic['topic']):
            """ Recursively list the fields in each message """
            print_topic_fields(topic['topic'], msg, 0)
            print('')
            break
    bag.close()
    sys.stdout.write("Found %u topics\n" % len(bag_topics))


def print_topic_fields(field_name, msg, depth):
    """ Recursive helper function for displaying information about a topic in a bag. This descends
        through the nested fields in a message, an displays the name of each level. The indentation
        increases depending on the depth of the nesting. As we recursively descend, we propagate the
        field name.

            There are three cases for processing each field in the bag.

            1.  The field could have other things in it, for example a pose's translation may have
                x, y, z components. Check for this by seeing if the message has slots.
            2.  The field could be a vector of other things. For instance, in the message file we
                could have an array of vectors, like geometry_msgs/Vector[] name. In this case,
                everything in the vector has the same format, so just look at the first message to
                extract the fields within the list.
            3.  The field could be a terminal leaf in the message, for instance the nsecs field in a
                header message. Just display the name.
    """
    if hasattr(msg, '__slots__'):
        """ This level of the message has more fields within it. Display the current
                level, and continue descending through the structure.
        """
        print(' ' * (depth * 2) + field_name)
        for slot in msg.__slots__:
            print_topic_fields(slot, getattr(msg, slot), depth + 1)
    elif isinstance(msg, list):
        """ We found a vector of field names. Display the information on the current
                level, and use the first element of the vector to display information
                about its content
        """
        if (len(msg) > 0) and hasattr(msg[0], '__slots__'):
            print(' ' * (depth * 2) + field_name + '[]')
            for slot in msg[0].__slots__:
                print_topic_fields(slot, getattr(msg[0], slot), depth + 1)
    else:
        """ We have reached a terminal leaf, i.e., and field with an actual value attached.
                Just print the name at this point.
        """
        print(' ' * (depth * 2) + field_name)


def display_stats(bag_name):
    """ Displays how many messages were published on each topic in the bag
    """
    """ Get the topics in the bag """
    bag_info = yaml.load(subprocess.Popen(
        ['rosbag', 'info', '--yaml', bag_name], stdout=subprocess.PIPE).communicate()[0])
    bag_topics = bag_info['topics']
    print('bag_info') 
    print(bag_info)
    bag = rosbag.Bag(bag_name)

    for topic in bag_topics:
        print("Topic: " + topic['topic'])
        print("\tType: " + topic['type'])
        print("\tCount: " + str(topic['messages']))
	print("\tCount: " + str(topic['messages']) + '\n')
    bag.close()


def round_to_1(x):
	return round(x, -int(math.floor(math.log10(abs(x)))))


def gcd(L):
	#return reduce(fractions.gcd, map(fractions.Fraction,L))
	return reduce(fractions.gcd, L)


#bag_reader3.py:259: RuntimeWarning: invalid value encountered in double_scalars
  #avg = summation / len(temp)
#math domain error
def find_hz(bag_name):
    global hz_dict, bag_topics
    bag = rosbag.Bag(bag_name)
    bag_info = yaml.load(subprocess.Popen(['rosbag', 'info', '--yaml', bag_name], stdout=subprocess.PIPE).communicate()[0])
    bag_topic_dict = bag_info['topics']
    temp = []
    #print(bag_topic_dict)
    for topic in bag_topic_dict:
        temp.append(topic['topic'])
    bag_topics = np.array(temp)
    bag_topics.sort()
    print("bag_topics: ")
    print(bag_topics)
    hz_dict = dict.fromkeys(bag_topics)
    bag_hzs = dict.fromkeys(bag_topics)
    for topic in bag_topics:
        hz_dict[topic] = []
    for topic, msg, t in bag.read_messages():
        temp = hz_dict[topic]
        temp.append(t)
        #if(topic == "/user_input"):
        #	print(msg)
        # 	print(temp)
    bag.close()
    
    nanoavgs = []
    for topic in bag_topics:
        timelist = hz_dict[topic]
        i = 0
        temp = []
        for t in timelist:
            if(i < len(timelist)-1):
                diff = timelist[i+1]-timelist[i]
                temp.append(diff.secs  + diff.nsecs * 10**-9)
            i = i+1
        summation = np.sum(temp)
        try:
            avg = summation / len(temp)
        except:
            avg = 0.0
        if(math.isnan(avg)):
            avg = 0.0
        f_avg = Fraction(str(long(avg))).limit_denominator(100)
        try:
            r_avg = round_to_1(avg)
        except Exception as e:
            print(e)
        if(math.isnan(r_avg)):
            avg = 0.0
        f_avg = Fraction(str(r_avg)).limit_denominator(1000)
        nanoavgs.append(f_avg)
        hz_dict[topic] = r_avg
    gcd_ans = gcd(nanoavgs)
    hz_dict['all'] = float(gcd_ans)
    print(hz_dict)
    return hz_dict

#'start'= 1554731872.79301
#t.tosec = 
# write_to_csv() for all topics in one file
def process_bag(bag_name):
    global bag_array
    global bag_info
    bag_info = yaml.load(subprocess.Popen(
        ['rosbag', 'info', '--yaml', bag_name], stdout=subprocess.PIPE).communicate()[0])
    print(bag_info)
    #print(bag_info["start"])
    #print(type(bag_info["start"]))
    #exit()
    start_time = rospy.Time.from_sec(bag_info["start"]) # convert from float to Time
    #TODO: check time conversion
    bag = rosbag.Bag(bag_name)
    """ Write the name of the fields as the first array in the 2D bag array """
    column_names = get_header_array(bag)
    """ Initialize the bag_array according to duration and universal Hz """
    initialize_bag_array()
    """ Go through the bag and and write every message into array """
    msg_count = 0
    for topic, msg, t in bag.read_messages(topics=bag_topics.tolist()):
        msg_count = msg_count + 1
        print("\n\n===============MSG #"+str(msg_count)+"===============")
        print("topic"+str(topic))
        print("msg"+str(msg))
        print("t:"+str(t))
        print("type of t:"+str(type(t)))
        
        time_in = t-start_time
        print("Time in: "+str(time_in))
        print("type of time_in: "+str(type(time_in)))
        row_index = get_row_index(start_time, t)
        parse_message_to_array(msg,topic,row_index)
        #if(msg_count > 20):
        #    break
    """ Cleanup """
    bag.close()
    

def get_row_index(start_time, t):
    print("start_time:"+str(start_time))
    print("start_time.to_sec():"+str(start_time.to_sec()))
    print("t:"+str(t))
    print("t.to_sec():"+str(t.to_sec()))
    print("t-start_time:"+str(t-start_time))
    print("t.to_sec()-start_time.to_sec():"+str(t.to_sec()-start_time.to_sec()))
    # Python standard library round() is dangerous due to floating point math
    #time_in = round(t.to_sec()-start_time.to_sec(), 2) 
    time_in = safe_round(t.to_sec()-start_time.to_sec(), 2)
    print("time_in(float):"+str(time_in))
    time_in = rospy.Time.from_sec(time_in)
    print("time_in(Time):"+str(time_in))
    row_index = float(time_in.to_sec() / hz_dict["all"])
    row_index = int(round(row_index))+1 # add 1 to accomodate headers at 0th position
    print("row_index:"+str(row_index))
    return row_index

def safe_round(num,sig_digs):
    return round(num+10**(-len(str(num))-1),sig_digs)

def parse_message_to_array(msg,topic,row_index):
    global bag_array
    global header_column_names
    global hz_dict
    """ Get row to write to by rounding time_in """
    print("write_message_to_array(msg,topic,time_in)")
    row = bag_array[row_index]
    column_values = {}
    column_mapping = field_names[topic]
    """ Build a dictionary of field names and their values. The field names
            match the message fields.
    """
    find_field_value('', msg, column_values, column_mapping)
    #column_mapping = ['.'.join([topic, col]) for col in column_mapping]
    print("\tcolumn_mapping: "+str(column_mapping))
    print("\tcolumn_values: "+str(column_values))
    """ write the discovered values to the bag_array """
    write_message_to_array(topic, column_mapping, column_values, row_index)


def write_message_to_array(topic, column_mapping, column_values, row_index):
    global bag_array
    global header_column_names
    for field in column_mapping:
        header = ".".join([topic, field])
        column_index = header_column_names.index(header)
        val = str(column_values["_"+field])
        val_string = val_string.replace('\n',' ')
        val_string = val_string.replace('\t',' ')
        val_string = val_string.replace(',',' ')
        val_string = val_string.replace('\r','')
        bag_array[row_index][column_index] = val_string
    print("bag_array["+str(row_index)+"]:")
    print(bag_array[row_index])
        

def commaless_array_string(arr):
    return_string = "["
    for string in arr:
        return_string = return_string + string +" "
    #return_string[len(return_string)-1]="]"
    return return_string +"]"


def initialize_bag_array():
    global bag_info
    global bag_array
    global hz_dict
    global header_column_names
    arr2_length = len(header_column_names)
    universal_hz = hz_dict["all"]
    duration = bag_info["duration"]
    rows = duration / universal_hz
    print("initialize_bag_array()")
    print("\trows (raw): "+str(rows))
    # Add 2 for rounding, 1 for headers row
    if(rows - (rows % 1) > 0):
        rows = int(rows) + 2
    else:
        rows = int(rows) + 1
    
    print("\trows: "+str(rows))
    bag_array = [["" for i in range(arr2_length)] for i in range(rows)]
    bag_array[0] = header_column_names
    #print("bag_array[0:3]:")
    #print(bag_array[0:3])
    

def get_header_array(bag):
    global field_names  #dict mapping topic to field names
    global header_column_names #array preserving order of topics and their fields in bag_array
    global bag_topics
    global bag_array
    print("INSIDE get_header_array")
    header_column_names = []
    field_names = dict((key,[]) for key in bag_topics)
    for topic, msg, _ in bag.read_messages(topics=bag_topics.tolist()):
        if(field_names[topic] == []):
            get_field_names('', msg, topic)
        if([] not in field_names.values()):
            break
    #print("field_names:")
    #print(field_names)
    for topic in bag_topics:
        fields = field_names[topic]
        for field in fields:
            header_column_names.append('.'.join([topic,field]))
            
    
def get_field_names(prefix, msg, topic):
    global field_names
    """ Recursive helper function for writing the header line. Works on the same principle as how
        the topics' fields are listed. Instead of printing them out to standard output, the parts of
        the messages are combined with underscores. When a leaf field is encountered, the entire
        prefix is printed.
    """
    if hasattr(msg, '__slots__'):
        for slot in msg.__slots__:
            get_field_names('_'.join([prefix, slot]), getattr(msg, slot), topic)
    elif isinstance(msg, list) and (len(msg) > 0) and hasattr(msg[0], '__slots__'):
        for slot in msg[0].__slots__:
            get_field_names('_'.join([prefix, slot]), getattr(msg[0], slot), topic)
    elif isinstance(msg, tuple):
        field_arr = field_names[topic]
        field_arr.append(prefix[1:])
        field_names[topic] = field_arr
    else:
        field_arr = field_names[topic]
        field_arr.append(prefix[1:])
        #trimmed_fields = [field[1:] for field in field_arr]
        field_names[topic]=field_arr


def find_field_value(prefix, msg, existing_values, column_names):
    """ Gets the value for all fields. Places the outputs and their field names in the
        existing_values dictionary. Works on the principle as listing the fields in the bag info
        command.
    """
    if hasattr(msg, '__slots__'):
        for slot in msg.__slots__:
            find_field_value('_'.join([prefix, slot]),
                             getattr(msg, slot), existing_values, column_names)
    elif isinstance(msg, list) and len(msg) > 0 and hasattr(msg[0], '__slots__'):
        """ When we encounter a field in the message that is a list, we need some special
            processing. If the field name we have built up so far matches something in our column
            names, we assume that we have reached a leaf of the message, and the field contains
            actual values. In that case, join all of the values in the field for a given field into
            a list. Otherwise, the field is a nested structure of other structures, and we have to
            keep going.
        """
        for slot in msg[0].__slots__:
            new_prefix = '_'.join([prefix, slot])
            if new_prefix in column_names:
                values = []
                for x in msg:
                    values.append(getattr(x, slot))
                existing_values[new_prefix] = values
            else:
                find_field_value(new_prefix, getattr(msg[0], slot), existing_values, column_names)
    else:
        existing_values[prefix] = msg


def write_to_csv(output_name):
    global bag_array
    f = open(output_name, 'w')
    """ Go through the bag array and and write every row out to the CSV file """
    print("\n\nWRITING TO CSV")
    i = 0
    for arr in bag_array:
        print("ROW "+str(i)+": "+str(arr))
        try:
            line = ','.join(arr) + '\n'
            f.write(line)
        except TypeError:
            print("TypeError occurred on "+str(arr))
            exit()
        i = i + 1
    #cribbed from write_header_line()
    #""" Alphabetize and write the column names to the output file, minus the leading underscore """
    #header_column_names.sort()
    #trimmed_names = [col[1:] for col in header_column_names]
    #header_line = ','.join(trimmed_names) + '\n'
    #output_file.write(header_line)
    
    """ Cleanup """
    f.close()


def main():
    global bag_array
    """ Main entry point for the function. Reads the command line arguments and performs the
        requested actions
    """
    # Parse the command line arguments
    argument_parser = build_parser()
    args = argument_parser.parse_args()
    if not validate_args(args):
        sys.exit()
    # Perform the requested actions on each bag file
    idx = 0
    for bag in args.bag:
        print('Processing bag: ' + bag)
        if args.info:
            display_bag_info(bag)
        elif args.stats:
            display_stats(bag)
        else:
            find_hz(bag)
            process_bag(bag)
            #print('\tProcessing topic: ' + topic)
            if args.out_file is None:
                out_file = os.path.splitext(bag)[0] + '.csv'
            else:
                out_file = args.out_file[idx]
            print("Writing to file "+out_file)
            write_to_csv(out_file)
            

if __name__ == "__main__":
    main()
            

